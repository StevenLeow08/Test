{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Capt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Col</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Countess</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Don</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dr</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jonkheer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Lady</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Major</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Miss</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mlle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mme</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mrs</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ms</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Rev</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sir</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female  male\n",
       "Title                 \n",
       "Capt           0     1\n",
       "Col            0     2\n",
       "Countess       1     0\n",
       "Don            0     1\n",
       "Dr             1     6\n",
       "Jonkheer       0     1\n",
       "Lady           1     0\n",
       "Major          0     2\n",
       "Master         0    40\n",
       "Miss         182     0\n",
       "Mlle           2     0\n",
       "Mme            1     0\n",
       "Mr             0   517\n",
       "Mrs          125     0\n",
       "Ms             1     0\n",
       "Rev            0     6\n",
       "Sir            0     1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(train_df['Title'], train_df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Master</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0.156673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Rare</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Title  Survived\n",
       "0  Master  0.575000\n",
       "1    Miss  0.702703\n",
       "2      Mr  0.156673\n",
       "3     Mrs  0.793651\n",
       "4    Rare  0.347826"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  Title  \n",
       "0      0         A/5 21171   7.2500   NaN        S      1  \n",
       "1      0          PC 17599  71.2833   C85        C      3  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S      2  \n",
       "3      0            113803  53.1000  C123        S      3  \n",
       "4      0            373450   8.0500   NaN        S      1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new family_size column\n",
    "df['Family_Size']=df['SibSp']+df['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Pclass','Sex','Embarked']\n",
    "cont_cols = ['Age','Family_Size','Fare']\n",
    "y_col = ['Survived']  # this column contains the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the three categorical columns to category dtypes.\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       int64\n",
       "Survived          int64\n",
       "Pclass         category\n",
       "Name             object\n",
       "Sex            category\n",
       "Age             float64\n",
       "SibSp             int64\n",
       "Parch             int64\n",
       "Ticket           object\n",
       "Fare            float64\n",
       "Cabin            object\n",
       "Embarked       category\n",
       "Family_Size       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pclass = 1:0 , 2:1 , 3:2\n",
    "# Sex = female:0 , male:1 \n",
    "# Embarked = C:0 , Q:1 , S:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 2],\n",
       "       [0, 0, 0],\n",
       "       [2, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [2, 1, 2]], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = df['Pclass'].cat.codes.values\n",
    "sex = df['Sex'].cat.codes.values\n",
    "ebrk = df['Embarked'].cat.codes.values\n",
    "\n",
    "cats = np.stack([pc, sex, ebrk], 1)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "missingvalues = SimpleImputer(missing_values = -1 , strategy = 'median', verbose = 0)  \n",
    "missingvalues = missingvalues.fit(cats[:,1:3])\n",
    "cats[:,1:3] = missingvalues.transform(cats[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 2],\n",
       "        [0, 0, 0],\n",
       "        [2, 0, 2],\n",
       "        [0, 0, 2],\n",
       "        [2, 1, 2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variables to a tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = np.stack([df[col].values for col in cont_cols], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "missingvalues = SimpleImputer(missing_values = np.nan, strategy = 'mean', verbose = 0)  \n",
    "missingvalues = missingvalues.fit(conts[:,0:1])\n",
    "conts[:,0:1] = missingvalues.transform(conts[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000,  1.0000,  7.2500],\n",
       "        [38.0000,  1.0000, 71.2833],\n",
       "        [26.0000,  0.0000,  7.9250],\n",
       "        [35.0000,  1.0000, 53.1000],\n",
       "        [35.0000,  0.0000,  8.0500]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert continuous variables to a tensor\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to a tensor\n",
    "y = torch.tensor(df[y_col].values).flatten()\n",
    "\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 2), (2, 1), (3, 2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will set embedding sizes for Pclass, Sex and Embarked\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(101)\n",
    "model = TabularModel(emb_szs, conts.shape[1], 2, [100,50], p=0.4) # out_sz = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(3, 2)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(3, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 891\n",
    "test_size = 191\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(con_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.84363061\n",
      "epoch:  26  loss: 0.65861762\n",
      "epoch:  51  loss: 0.60503906\n",
      "epoch:  76  loss: 0.59684759\n",
      "epoch: 101  loss: 0.57633549\n",
      "epoch: 126  loss: 0.56821519\n",
      "epoch: 151  loss: 0.55181152\n",
      "epoch: 176  loss: 0.57446468\n",
      "epoch: 200  loss: 0.53789479\n",
      "\n",
      "Duration: 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 200\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.51417935\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT               ARGMAX  Y_TEST\n",
      "tensor([-0.4685,  0.3464])    1      1   \n",
      "tensor([-0.5895,  0.0848])    1      1   \n",
      "tensor([0.5475, 0.8200])      1      0   \n",
      "tensor([ 0.1495, -1.1847])    0      0   \n",
      "tensor([0.2886, 0.2120])      0      0   \n",
      "tensor([-0.6837, -0.0866])    1      0   \n",
      "tensor([-0.3021, -1.2670])    0      1   \n",
      "tensor([0.2529, 0.1128])      0      1   \n",
      "tensor([-0.7946,  0.3969])    1      1   \n",
      "tensor([ 0.8101, -0.7818])    0      1   \n",
      "tensor([0.1319, 0.1903])      1      1   \n",
      "tensor([-0.2503,  0.2405])    1      0   \n",
      "tensor([-0.2012, -0.6219])    0      1   \n",
      "tensor([ 0.7803, -0.6024])    0      0   \n",
      "tensor([ 1.3680, -0.5207])    0      0   \n",
      "tensor([0.3418, 0.1618])      0      0   \n",
      "tensor([0.1178, 1.9511])      1      1   \n",
      "tensor([-0.4506, -1.2895])    0      1   \n",
      "tensor([0.3965, 0.7420])      1      0   \n",
      "tensor([ 0.4298, -0.7398])    0      0   \n",
      "tensor([-0.9765, -0.2184])    1      1   \n",
      "tensor([ 0.9589, -0.6388])    0      0   \n",
      "tensor([ 1.0082, -0.6269])    0      0   \n",
      "tensor([ 0.1627, -0.4499])    0      0   \n",
      "tensor([ 0.0982, -0.6246])    0      1   \n",
      "tensor([0.7571, 0.0469])      0      0   \n",
      "tensor([ 0.2430, -0.0572])    0      1   \n",
      "tensor([-1.0427,  0.3078])    1      1   \n",
      "tensor([ 0.1764, -0.4434])    0      0   \n",
      "tensor([ 0.6065, -0.2491])    0      0   \n",
      "tensor([-1.3646,  0.5454])    1      1   \n",
      "tensor([0.2724, 0.3686])      1      0   \n",
      "tensor([ 1.2825, -1.1782])    0      0   \n",
      "tensor([-0.7926, -0.9563])    0      0   \n",
      "tensor([-0.0180, -0.3118])    0      0   \n",
      "tensor([ 0.1289, -1.1495])    0      0   \n",
      "tensor([1.6761, 0.5604])      0      0   \n",
      "tensor([0.0430, 1.3950])      1      1   \n",
      "tensor([-0.3876, -1.0664])    0      0   \n",
      "tensor([ 0.3802, -0.7747])    0      0   \n",
      "tensor([ 0.0857, -0.5319])    0      1   \n",
      "tensor([-0.8778,  1.0669])    1      0   \n",
      "tensor([ 0.3641, -0.0453])    0      1   \n",
      "tensor([ 0.8454, -0.8532])    0      0   \n",
      "tensor([ 0.0870, -0.5284])    0      1   \n",
      "tensor([ 0.3829, -0.3869])    0      0   \n",
      "tensor([ 0.8014, -0.7167])    0      0   \n",
      "tensor([ 0.3365, -0.1764])    0      1   \n",
      "tensor([-0.2166, -0.5052])    0      0   \n",
      "tensor([ 0.9412, -1.4644])    0      0   \n",
      "tensor([-0.6576,  0.5409])    1      1   \n",
      "tensor([-0.6150,  0.9662])    1      1   \n",
      "tensor([ 0.0320, -0.3333])    0      0   \n",
      "tensor([ 1.3477, -0.4071])    0      0   \n",
      "tensor([ 0.2844, -0.1557])    0      1   \n",
      "tensor([-0.4477,  0.4617])    1      1   \n",
      "tensor([ 1.1388, -0.1120])    0      0   \n",
      "tensor([ 0.7720, -0.4027])    0      0   \n",
      "tensor([ 0.3861, -0.4948])    0      0   \n",
      "tensor([-0.6811,  0.6847])    1      1   \n",
      "tensor([ 1.0716, -0.6107])    0      0   \n",
      "tensor([ 0.2487, -0.2963])    0      0   \n",
      "tensor([ 0.0989, -0.7309])    0      1   \n",
      "tensor([-1.8067,  0.0699])    1      1   \n",
      "tensor([ 1.1641, -0.4156])    0      0   \n",
      "tensor([-0.1635,  0.9096])    1      1   \n",
      "tensor([-0.2447, -0.7537])    0      0   \n",
      "tensor([-1.1791,  0.6760])    1      0   \n",
      "tensor([ 1.6523, -0.2946])    0      0   \n",
      "tensor([ 0.6049, -1.5048])    0      0   \n",
      "tensor([ 1.2319, -0.3837])    0      0   \n",
      "tensor([ 1.8402, -0.7503])    0      0   \n",
      "tensor([ 0.0811, -0.3181])    0      0   \n",
      "tensor([ 1.0168, -1.0081])    0      0   \n",
      "tensor([ 0.2183, -0.6245])    0      1   \n",
      "tensor([ 0.2902, -0.1013])    0      0   \n",
      "tensor([ 0.7319, -0.7863])    0      0   \n",
      "tensor([0.2488, 0.5692])      1      1   \n",
      "tensor([ 0.9833, -0.5954])    0      0   \n",
      "tensor([-1.0045,  0.7518])    1      1   \n",
      "tensor([0.3127, 0.1985])      0      1   \n",
      "tensor([-0.5502,  0.8247])    1      1   \n",
      "tensor([ 0.5809, -0.5505])    0      0   \n",
      "tensor([-0.0856, -0.3527])    0      0   \n",
      "tensor([ 1.6640, -0.8236])    0      0   \n",
      "tensor([0.6990, 0.0707])      0      0   \n",
      "tensor([ 0.7039, -0.4725])    0      1   \n",
      "tensor([ 0.4486, -1.3038])    0      0   \n",
      "tensor([ 0.0980, -0.2469])    0      1   \n",
      "tensor([-0.7541,  0.1989])    1      0   \n",
      "tensor([ 1.1089, -0.6184])    0      0   \n",
      "tensor([-0.2516,  0.0447])    1      0   \n",
      "tensor([ 1.7405, -1.1595])    0      0   \n",
      "tensor([0.1498, 0.3446])      1      0   \n",
      "tensor([ 0.8063, -0.7945])    0      0   \n",
      "tensor([-0.0657, -0.5590])    0      0   \n",
      "tensor([-0.5867, -0.3549])    1      1   \n",
      "tensor([ 0.2091, -0.3958])    0      1   \n",
      "tensor([-0.3644, -0.6482])    0      0   \n",
      "tensor([-0.1640,  0.0681])    1      0   \n",
      "tensor([-0.1649, -0.2459])    0      0   \n",
      "tensor([-0.7901, -0.0871])    1      1   \n",
      "tensor([ 0.0764, -0.2032])    0      1   \n",
      "tensor([-0.5895,  0.1480])    1      1   \n",
      "tensor([-0.6999, -0.6505])    1      1   \n",
      "tensor([ 0.7179, -0.9902])    0      0   \n",
      "tensor([ 0.6388, -1.3599])    0      0   \n",
      "tensor([ 0.5733, -0.2228])    0      0   \n",
      "tensor([-0.3578, -0.5382])    0      0   \n",
      "tensor([-0.2638,  0.0181])    1      1   \n",
      "tensor([ 0.4335, -0.4357])    0      0   \n",
      "tensor([ 0.4718, -1.4481])    0      0   \n",
      "tensor([ 0.9543, -0.7341])    0      0   \n",
      "tensor([-0.0500, -0.2691])    0      0   \n",
      "tensor([ 0.1677, -0.4468])    0      0   \n",
      "tensor([ 1.0082, -1.1969])    0      0   \n",
      "tensor([ 0.1884, -0.3330])    0      0   \n",
      "tensor([ 0.0723, -0.4646])    0      0   \n",
      "tensor([ 1.3961, -1.0772])    0      0   \n",
      "tensor([ 0.3916, -0.2907])    0      0   \n",
      "tensor([-0.4068,  0.5895])    1      1   \n",
      "tensor([ 0.8067, -0.8253])    0      1   \n",
      "tensor([ 1.4186, -0.5161])    0      0   \n",
      "tensor([-0.1241, -0.3647])    0      1   \n",
      "tensor([1.0852, 0.5459])      0      0   \n",
      "tensor([-0.7179, -0.7992])    0      0   \n",
      "tensor([-0.0713, -0.6591])    0      0   \n",
      "tensor([0.4155, 2.2439])      1      1   \n",
      "tensor([ 0.3472, -1.4084])    0      1   \n",
      "tensor([-0.5978, -0.4018])    1      1   \n",
      "tensor([-0.1728,  1.0787])    1      1   \n",
      "tensor([0.2140, 0.6097])      1      1   \n",
      "tensor([-0.4249, -0.7401])    0      0   \n",
      "tensor([ 0.8633, -0.1406])    0      0   \n",
      "tensor([ 0.9713, -0.2689])    0      0   \n",
      "tensor([-0.0926,  0.6327])    1      1   \n",
      "tensor([ 0.3411, -0.8374])    0      0   \n",
      "tensor([ 0.4772, -0.8676])    0      0   \n",
      "tensor([-0.1168, -0.4951])    0      1   \n",
      "tensor([0.0038, 0.4886])      1      1   \n",
      "tensor([0.2013, 0.1088])      0      0   \n",
      "tensor([-0.5276,  0.8838])    1      0   \n",
      "tensor([-0.4664, -0.5671])    0      1   \n",
      "tensor([ 1.0053, -1.2156])    0      0   \n",
      "tensor([ 0.5003, -1.0585])    0      0   \n",
      "tensor([ 0.9226, -0.9202])    0      0   \n",
      "tensor([ 2.0466, -0.5698])    0      0   \n",
      "tensor([ 0.7172, -1.0582])    0      0   \n",
      "tensor([-0.6230,  0.3547])    1      0   \n",
      "tensor([0.4015, 0.8854])      1      1   \n",
      "tensor([ 1.2370, -0.9078])    0      0   \n",
      "tensor([ 1.3267, -1.1183])    0      0   \n",
      "tensor([-0.7902,  0.2223])    1      0   \n",
      "tensor([0.1532, 0.8347])      1      1   \n",
      "tensor([-0.0687, -0.5689])    0      0   \n",
      "tensor([-0.4327, -0.1149])    1      1   \n",
      "tensor([-1.8964,  0.3881])    1      1   \n",
      "tensor([ 0.5639, -1.0583])    0      1   \n",
      "tensor([-0.0901,  1.6034])    1      1   \n",
      "tensor([1.3836, 0.4128])      0      0   \n",
      "tensor([ 2.6275, -0.4840])    0      0   \n",
      "tensor([ 0.4368, -0.3312])    0      0   \n",
      "tensor([-0.2872, -0.8841])    0      1   \n",
      "tensor([ 1.8997, -1.3684])    0      0   \n",
      "tensor([ 0.3299, -0.0833])    0      0   \n",
      "tensor([-0.0048, -0.4328])    0      1   \n",
      "tensor([ 0.5419, -0.0473])    0      1   \n",
      "tensor([-0.0244, -0.5026])    0      0   \n",
      "tensor([ 0.9074, -0.5418])    0      0   \n",
      "tensor([ 0.3545, -0.0478])    0      1   \n",
      "tensor([ 0.8544, -0.6706])    0      0   \n",
      "tensor([ 0.1403, -0.4305])    0      1   \n",
      "tensor([-0.0486, -0.5751])    0      0   \n",
      "tensor([ 1.5679, -0.3888])    0      0   \n",
      "tensor([0.6669, 0.0209])      0      1   \n",
      "tensor([0.1330, 0.3006])      1      1   \n",
      "tensor([ 0.4624, -0.5693])    0      0   \n",
      "tensor([ 0.6543, -0.9110])    0      0   \n",
      "tensor([ 0.7024, -0.7022])    0      0   \n",
      "tensor([0.0052, 2.0261])      1      1   \n",
      "tensor([-0.5946,  0.0755])    1      1   \n",
      "tensor([-0.2480, -1.3571])    0      0   \n",
      "tensor([0.6611, 0.1185])      0      0   \n",
      "tensor([0.1992, 0.0137])      0      0   \n",
      "tensor([ 0.7776, -0.1189])    0      0   \n",
      "tensor([1.3980, 0.1827])      0      0   \n",
      "tensor([ 0.1189, -0.9965])    0      0   \n",
      "tensor([-0.7434,  0.2459])    1      1   \n",
      "tensor([ 0.0079, -0.7844])    0      0   \n",
      "tensor([ 0.0265, -0.8464])    0      1   \n",
      "tensor([ 0.0604, -1.3204])    0      0   \n",
      "\n",
      "145 out of 191 = 75.92% correct\n"
     ]
    }
   ],
   "source": [
    "rows = 191\n",
    "correct = 0\n",
    "print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\n",
    "for i in range(rows):\n",
    "    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_test[i]:^7}')\n",
    "    if y_val[i].argmax().item() == y_test[i]:\n",
    "        correct += 1\n",
    "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to save the model only after the training has happened!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TitanicModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT NEW DATA\n",
    "df2 = pd.read_csv('test.csv')\n",
    "    \n",
    "# PREPROCESS THE DATA\n",
    "df2['Family_Size']= df2['SibSp'] + df2['Parch']\n",
    "\n",
    "# CREATE CAT AND CONT TENSORS\n",
    "cat_cols = ['Pclass','Sex','Embarked']\n",
    "cont_cols = ['Age','Family_Size','Fare']\n",
    "\n",
    "# Convert the three categorical columns to category dtypes.\n",
    "for cat in cat_cols:\n",
    "    df2[cat] = df2[cat].astype('category')\n",
    "    \n",
    "pc = df2['Pclass'].cat.codes.values\n",
    "sex = df2['Sex'].cat.codes.values\n",
    "ebrk = df2['Embarked'].cat.codes.values\n",
    "\n",
    "cats2 = np.stack([pc, sex, ebrk], 1)\n",
    "cats2 = torch.tensor(cats2, dtype=torch.int64)\n",
    "    \n",
    "conts2 = np.stack([df2[col].values for col in cont_cols], 1)\n",
    "from sklearn.impute import SimpleImputer\n",
    "missingvalues = SimpleImputer(missing_values = np.nan, strategy = 'mean', verbose = 0)  \n",
    "missingvalues = missingvalues.fit(conts2[:,0:3])\n",
    "conts2[:,0:3] = missingvalues.transform(conts2[:,0:3])\n",
    "conts2 = torch.tensor(conts2, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(3, 2)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(3, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = TabularModel(emb_szs, conts2.shape[1], 2, [100,50], p=0.4)\n",
    "model2.load_state_dict(torch.load('TitanicModel.pt'));\n",
    "model2.eval() # be sure to run this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT               ARGMAX\n",
      "tensor([ 0.2999, -0.8735])    0   \n",
      "tensor([ 0.4501, -0.5728])    0   \n",
      "tensor([ 1.1922, -1.0289])    0   \n",
      "tensor([ 0.4000, -0.7844])    0   \n",
      "tensor([-0.0418, -0.0163])    1   \n",
      "tensor([ 0.1286, -0.3787])    0   \n",
      "tensor([-0.5117, -0.3642])    1   \n",
      "tensor([ 0.3137, -0.0470])    0   \n",
      "tensor([ 0.2685, -0.0883])    0   \n",
      "tensor([ 0.1181, -0.1573])    0   \n",
      "tensor([ 0.4623, -0.8710])    0   \n",
      "tensor([-0.0218, -0.7702])    0   \n",
      "tensor([-0.6404,  0.8244])    1   \n",
      "tensor([ 0.7754, -0.4730])    0   \n",
      "tensor([-0.6790,  0.1883])    1   \n",
      "tensor([-0.0461,  0.2528])    1   \n",
      "tensor([ 0.2569, -0.7802])    0   \n",
      "tensor([ 0.5198, -0.5888])    0   \n",
      "tensor([ 0.0972, -0.3613])    0   \n",
      "tensor([ 0.4764, -0.7371])    0   \n",
      "tensor([-0.4004, -0.3656])    1   \n",
      "tensor([-0.0161, -0.1567])    0   \n",
      "tensor([-0.4884,  0.2868])    1   \n",
      "tensor([-0.2494,  0.6429])    1   \n",
      "tensor([-0.3296,  0.7342])    1   \n",
      "tensor([ 0.7907, -0.7611])    0   \n",
      "tensor([-0.4206,  0.8825])    1   \n",
      "tensor([ 0.5534, -0.6356])    0   \n",
      "tensor([-0.0819, -0.6203])    0   \n",
      "tensor([ 0.3001, -0.3091])    0   \n",
      "tensor([ 0.4242, -0.5977])    0   \n",
      "tensor([ 0.1938, -0.0137])    0   \n",
      "tensor([ 0.2984, -0.1290])    0   \n",
      "tensor([ 0.1930, -0.0839])    0   \n",
      "tensor([-0.2895,  0.3345])    1   \n",
      "tensor([ 0.4510, -0.4909])    0   \n",
      "tensor([ 0.0838, -0.5894])    0   \n",
      "tensor([ 0.0348, -0.2637])    0   \n",
      "tensor([ 0.3354, -0.7185])    0   \n",
      "tensor([-0.4609, -0.1196])    1   \n",
      "tensor([ 0.6070, -0.7735])    0   \n",
      "tensor([-0.1193, -0.3827])    0   \n",
      "tensor([ 0.5329, -1.0126])    0   \n",
      "tensor([-0.1579, -0.3792])    0   \n",
      "tensor([-0.6166,  0.1708])    1   \n",
      "tensor([ 0.3795, -0.7454])    0   \n",
      "tensor([ 0.0217, -0.6366])    0   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([-0.8955, -0.1049])    1   \n",
      "tensor([ 0.2375, -0.1579])    0   \n",
      "tensor([-0.4917,  0.3222])    1   \n",
      "tensor([ 0.5982, -0.6049])    0   \n",
      "tensor([-0.0278,  0.2536])    1   \n",
      "tensor([0.1236, 0.2011])      1   \n",
      "tensor([ 0.6121, -0.6206])    0   \n",
      "tensor([ 1.2053, -0.8787])    0   \n",
      "tensor([ 0.4734, -0.9843])    0   \n",
      "tensor([ 0.3873, -0.7501])    0   \n",
      "tensor([ 0.3959, -0.6218])    0   \n",
      "tensor([-0.7475,  0.8414])    1   \n",
      "tensor([ 0.2091, -0.5461])    0   \n",
      "tensor([ 0.2356, -0.7703])    0   \n",
      "tensor([ 0.2275, -0.5883])    0   \n",
      "tensor([-0.4769, -0.0699])    1   \n",
      "tensor([0.1127, 0.6603])      1   \n",
      "tensor([-0.3894, -0.2160])    1   \n",
      "tensor([-0.4691,  0.1431])    1   \n",
      "tensor([-0.3098, -0.5569])    0   \n",
      "tensor([ 0.0065, -0.2804])    0   \n",
      "tensor([ 0.2079, -0.0559])    0   \n",
      "tensor([-0.4857, -0.1572])    1   \n",
      "tensor([ 0.2895, -0.6565])    0   \n",
      "tensor([ 0.0845, -0.5522])    0   \n",
      "tensor([-0.0105, -0.2195])    0   \n",
      "tensor([-0.7443,  0.7943])    1   \n",
      "tensor([-0.5192,  0.6290])    1   \n",
      "tensor([ 0.4575, -0.8688])    0   \n",
      "tensor([ 0.0807, -0.2481])    0   \n",
      "tensor([ 0.2647, -0.7405])    0   \n",
      "tensor([-0.4857, -0.1572])    1   \n",
      "tensor([-0.1168,  0.6407])    1   \n",
      "tensor([-0.8599, -0.0323])    1   \n",
      "tensor([-0.0219, -0.8294])    0   \n",
      "tensor([ 0.4623, -0.8710])    0   \n",
      "tensor([ 0.0673, -0.6626])    0   \n",
      "tensor([ 0.4695, -0.5914])    0   \n",
      "tensor([-0.5103, -0.2637])    1   \n",
      "tensor([ 0.0561, -0.1219])    0   \n",
      "tensor([-0.5110, -0.3708])    1   \n",
      "tensor([-0.2698,  0.5318])    1   \n",
      "tensor([-0.1625, -0.0538])    1   \n",
      "tensor([ 0.4659, -0.8728])    0   \n",
      "tensor([-0.4323,  0.2592])    1   \n",
      "tensor([ 0.4575, -0.8688])    0   \n",
      "tensor([-0.0321, -0.1247])    0   \n",
      "tensor([ 0.3832, -0.7476])    0   \n",
      "tensor([-0.4987, -0.2407])    1   \n",
      "tensor([ 0.4539, -0.8453])    0   \n",
      "tensor([ 0.0509, -0.2412])    0   \n",
      "tensor([ 0.4654, -0.9356])    0   \n",
      "tensor([-0.6581,  0.2113])    1   \n",
      "tensor([ 0.1733, -0.2472])    0   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([ 0.4057, -0.7736])    0   \n",
      "tensor([-0.0955,  0.4303])    1   \n",
      "tensor([ 0.0835, -0.5594])    0   \n",
      "tensor([-0.1275, -0.4015])    0   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([ 0.4374, -0.8591])    0   \n",
      "tensor([ 0.3918, -0.4596])    0   \n",
      "tensor([ 0.6078, -0.7100])    0   \n",
      "tensor([-0.5115, -0.3706])    1   \n",
      "tensor([-0.3206, -0.0287])    1   \n",
      "tensor([-0.4660,  0.1069])    1   \n",
      "tensor([-1.1834,  0.2792])    1   \n",
      "tensor([ 0.1941, -0.1867])    0   \n",
      "tensor([ 0.7098, -0.8470])    0   \n",
      "tensor([-0.4287,  0.7142])    1   \n",
      "tensor([-0.4212,  0.2195])    1   \n",
      "tensor([-0.4087,  0.1532])    1   \n",
      "tensor([0.1182, 0.3157])      1   \n",
      "tensor([ 0.4946, -0.7252])    0   \n",
      "tensor([-0.5924,  0.4689])    1   \n",
      "tensor([ 0.4582, -0.8356])    0   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([-0.2825,  0.1612])    1   \n",
      "tensor([ 0.3199, -0.6780])    0   \n",
      "tensor([-0.2709, -0.0890])    1   \n",
      "tensor([ 0.2732, -0.8825])    0   \n",
      "tensor([ 0.3571, -0.7178])    0   \n",
      "tensor([ 0.4624, -0.9122])    0   \n",
      "tensor([ 0.0732, -0.7881])    0   \n",
      "tensor([ 0.5146, -0.2297])    0   \n",
      "tensor([ 0.5780, -0.7553])    0   \n",
      "tensor([ 0.5553, -1.0004])    0   \n",
      "tensor([ 0.3625, -0.7211])    0   \n",
      "tensor([ 0.6411, -0.7387])    0   \n",
      "tensor([ 0.3223, -0.6378])    0   \n",
      "tensor([ 0.0571, -0.3459])    0   \n",
      "tensor([ 2.1070, -1.1059])    0   \n",
      "tensor([ 0.9183, -1.0258])    0   \n",
      "tensor([-1.0354,  0.4015])    1   \n",
      "tensor([-0.1232,  0.3205])    1   \n",
      "tensor([-0.0208, -0.4636])    0   \n",
      "tensor([-0.0256, -0.7063])    0   \n",
      "tensor([ 0.7127, -0.4705])    0   \n",
      "tensor([-0.4091,  0.0065])    1   \n",
      "tensor([ 0.3128, -0.6735])    0   \n",
      "tensor([-0.1193, -0.3827])    0   \n",
      "tensor([ 0.4943, -0.1179])    0   \n",
      "tensor([-0.4472,  0.9128])    1   \n",
      "tensor([ 0.6963, -0.8183])    0   \n",
      "tensor([ 0.1430, -0.6595])    0   \n",
      "tensor([ 0.3272, -0.2337])    0   \n",
      "tensor([ 1.0868, -1.1930])    0   \n",
      "tensor([ 0.3710, -0.7263])    0   \n",
      "tensor([-1.0753,  0.3294])    1   \n",
      "tensor([ 0.0622, -0.3500])    0   \n",
      "tensor([-0.0256, -0.7063])    0   \n",
      "tensor([ 0.0240, -0.1017])    0   \n",
      "tensor([-0.5108, -0.3709])    1   \n",
      "tensor([-0.0966,  0.6088])    1   \n",
      "tensor([-0.1077, -0.3061])    0   \n",
      "tensor([ 0.4879, -0.8856])    0   \n",
      "tensor([ 0.2505, -0.8855])    0   \n",
      "tensor([-0.1432,  0.0478])    1   \n",
      "tensor([-0.3213, -0.4321])    0   \n",
      "tensor([ 0.5184, -0.5551])    0   \n",
      "tensor([-0.2221,  0.1091])    1   \n",
      "tensor([ 0.0279, -0.2931])    0   \n",
      "tensor([ 0.4723, -0.8765])    0   \n",
      "tensor([ 0.6512, -0.7507])    0   \n",
      "tensor([ 0.2487, -0.4772])    0   \n",
      "tensor([ 0.7025, -0.8314])    0   \n",
      "tensor([ 1.8555, -0.9585])    0   \n",
      "tensor([-0.4799,  0.5426])    1   \n",
      "tensor([-0.4775,  0.3570])    1   \n",
      "tensor([-0.3687, -0.3922])    0   \n",
      "tensor([0.0465, 0.2382])      1   \n",
      "tensor([-0.7281,  0.0463])    1   \n",
      "tensor([ 0.2647, -0.7405])    0   \n",
      "tensor([-0.4434,  0.2372])    1   \n",
      "tensor([-0.4909,  0.9241])    1   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([-0.5237,  0.8567])    1   \n",
      "tensor([ 0.1705, -0.8505])    0   \n",
      "tensor([-0.3319,  0.2823])    1   \n",
      "tensor([ 0.2511, -0.3854])    0   \n",
      "tensor([ 2.4573, -1.4584])    0   \n",
      "tensor([ 0.2418, -0.8774])    0   \n",
      "tensor([ 0.2799, -0.3572])    0   \n",
      "tensor([-0.1100, -0.3926])    0   \n",
      "tensor([-0.0441, -0.0518])    0   \n",
      "tensor([ 1.1008, -1.0003])    0   \n",
      "tensor([-0.3271,  0.2549])    1   \n",
      "tensor([ 0.4711, -0.9387])    0   \n",
      "tensor([-0.1410,  1.0206])    1   \n",
      "tensor([ 0.0635, -0.1277])    0   \n",
      "tensor([ 0.4377, -0.6068])    0   \n",
      "tensor([ 0.0822, -0.5880])    0   \n",
      "tensor([-0.5902, -0.2929])    1   \n",
      "tensor([-0.3297,  0.4479])    1   \n",
      "tensor([-0.7715,  0.4451])    1   \n",
      "tensor([-0.4426,  0.6361])    1   \n",
      "tensor([ 0.4081, -0.6497])    0   \n",
      "tensor([ 0.0264, -0.3112])    0   \n",
      "tensor([-0.4067, -0.4440])    0   \n",
      "tensor([ 0.4281, -0.6246])    0   \n",
      "tensor([-0.2260,  0.0160])    1   \n",
      "tensor([ 0.3804, -0.7459])    0   \n",
      "tensor([ 0.1086, -0.6657])    0   \n",
      "tensor([ 0.4865, -0.8847])    0   \n",
      "tensor([-0.3696,  0.3309])    1   \n",
      "tensor([ 0.0440, -0.2883])    0   \n",
      "tensor([ 1.4744, -0.9197])    0   \n",
      "tensor([-0.2834, -0.4482])    0   \n",
      "tensor([-0.5130, -0.3700])    1   \n",
      "tensor([-0.5413, -0.0859])    1   \n",
      "tensor([-0.7383,  0.7288])    1   \n",
      "tensor([ 0.4575, -0.8688])    0   \n",
      "tensor([ 0.2053, -0.1035])    0   \n",
      "tensor([ 0.2852, -0.6538])    0   \n",
      "tensor([ 0.0539, -0.2778])    0   \n",
      "tensor([ 0.2923, -0.6583])    0   \n",
      "tensor([-0.2553, -0.5038])    0   \n",
      "tensor([ 0.0643, -0.0340])    0   \n",
      "tensor([ 0.3422, -0.6999])    0   \n",
      "tensor([-0.5110, -0.3708])    1   \n",
      "tensor([ 0.2938, -0.9742])    0   \n",
      "tensor([ 0.2268, -0.8237])    0   \n",
      "tensor([-0.2224,  0.4155])    1   \n",
      "tensor([-0.2565,  0.6889])    1   \n",
      "tensor([ 0.3647, -0.5765])    0   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1405, -0.7605])    0   \n",
      "tensor([-0.4485,  0.1325])    1   \n",
      "tensor([ 0.2672, -0.6374])    0   \n",
      "tensor([-0.5192, -0.3080])    1   \n",
      "tensor([ 0.4982, -0.5534])    0   \n",
      "tensor([-0.1865,  0.3586])    1   \n",
      "tensor([-0.8761,  0.3595])    1   \n",
      "tensor([-0.2566, -0.5294])    0   \n",
      "tensor([-0.0191,  0.0960])    1   \n",
      "tensor([-0.5239,  0.3240])    1   \n",
      "tensor([ 0.4625, -0.8711])    0   \n",
      "tensor([ 0.6072, -0.4002])    0   \n",
      "tensor([-0.2367, -0.0834])    1   \n",
      "tensor([-0.2454, -0.0459])    1   \n",
      "tensor([ 0.5049, -0.2237])    0   \n",
      "tensor([-0.4087,  0.1532])    1   \n",
      "tensor([ 0.2007, -0.2663])    0   \n",
      "tensor([-0.4247,  0.6991])    1   \n",
      "tensor([ 0.2653, -0.6362])    0   \n",
      "tensor([-0.3052,  0.7919])    1   \n",
      "tensor([ 0.3215, -0.6960])    0   \n",
      "tensor([ 0.4222, -0.9008])    0   \n",
      "tensor([ 0.4723, -0.8765])    0   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([ 0.4351, -0.8219])    0   \n",
      "tensor([ 0.0563, -0.1007])    0   \n",
      "tensor([ 0.2929, -0.6587])    0   \n",
      "tensor([ 0.4607, -0.7294])    0   \n",
      "tensor([ 0.2907, -0.6573])    0   \n",
      "tensor([-0.1644,  0.2512])    1   \n",
      "tensor([-0.3813,  0.6799])    1   \n",
      "tensor([ 0.6524, -0.6692])    0   \n",
      "tensor([ 0.4623, -0.8710])    0   \n",
      "tensor([ 0.3647, -0.8756])    0   \n",
      "tensor([ 0.4723, -0.8765])    0   \n",
      "tensor([ 0.0838, -0.5894])    0   \n",
      "tensor([ 0.1879, -0.5352])    0   \n",
      "tensor([-0.5479, -0.1484])    1   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([-0.5016,  0.9212])    1   \n",
      "tensor([-0.4829, -0.2179])    1   \n",
      "tensor([ 0.7025, -0.8315])    0   \n",
      "tensor([-0.4193,  0.3846])    1   \n",
      "tensor([ 0.3572, -0.7348])    0   \n",
      "tensor([ 0.2838, -0.4863])    0   \n",
      "tensor([ 0.3606, -0.3418])    0   \n",
      "tensor([ 0.4373, -0.5926])    0   \n",
      "tensor([ 0.0411, -0.3331])    0   \n",
      "tensor([-0.3188,  0.4252])    1   \n",
      "tensor([-0.5110, -0.3708])    1   \n",
      "tensor([-0.2191,  0.7803])    1   \n",
      "tensor([-0.4643,  0.6881])    1   \n",
      "tensor([ 0.4921, -1.0141])    0   \n",
      "tensor([ 0.4808, -0.8814])    0   \n",
      "tensor([-0.6133,  0.4016])    1   \n",
      "tensor([ 0.7025, -0.8314])    0   \n",
      "tensor([ 0.4575, -0.8688])    0   \n",
      "tensor([-0.2899, -0.1828])    1   \n",
      "tensor([-0.5011, -0.3684])    1   \n",
      "tensor([ 0.7025, -0.8314])    0   \n",
      "tensor([-0.1456,  0.0017])    1   \n",
      "tensor([ 0.4308, -0.9786])    0   \n",
      "tensor([ 0.4022, -0.7716])    0   \n",
      "tensor([-0.3697,  1.2744])    1   \n",
      "tensor([ 0.3001, -0.3091])    0   \n",
      "tensor([-0.3470, -0.0783])    1   \n",
      "tensor([ 0.4558, -0.8464])    0   \n",
      "tensor([ 0.4702, -0.9168])    0   \n",
      "tensor([ 0.6201, -0.6301])    0   \n",
      "tensor([ 0.4083, -0.6142])    0   \n",
      "tensor([ 0.3400, -0.7073])    0   \n",
      "tensor([-0.5110, -0.3708])    1   \n",
      "tensor([ 0.2635, -0.3313])    0   \n",
      "tensor([-0.2663,  0.1033])    1   \n",
      "tensor([-0.1756,  0.4836])    1   \n",
      "tensor([-0.2110, -0.0112])    1   \n",
      "tensor([ 0.2096, -0.4937])    0   \n",
      "tensor([ 0.2024, -0.5737])    0   \n",
      "tensor([ 0.5422, -0.6200])    0   \n",
      "tensor([ 0.4716, -0.8761])    0   \n",
      "tensor([-0.3672, -0.4908])    0   \n",
      "tensor([-1.1108,  0.2656])    1   \n",
      "tensor([-0.4662,  0.2026])    1   \n",
      "tensor([-0.7605,  0.1472])    1   \n",
      "tensor([ 0.4428, -0.5179])    0   \n",
      "tensor([ 0.4233, -0.7982])    0   \n",
      "tensor([ 0.1270, -0.0086])    0   \n",
      "tensor([ 0.4057, -0.7736])    0   \n",
      "tensor([ 0.6107, -0.7027])    0   \n",
      "tensor([ 0.3223, -0.6378])    0   \n",
      "tensor([-0.1051, -0.4812])    0   \n",
      "tensor([-1.2351,  0.2684])    1   \n",
      "tensor([ 0.3626, -0.7132])    0   \n",
      "tensor([-0.3996,  0.4308])    1   \n",
      "tensor([-0.5760, -0.1066])    1   \n",
      "tensor([ 0.2300, -0.2642])    0   \n",
      "tensor([ 0.3592, -0.5430])    0   \n",
      "tensor([-0.0676,  0.1001])    1   \n",
      "tensor([ 0.0305, -0.5308])    0   \n",
      "tensor([ 0.7025, -0.8315])    0   \n",
      "tensor([-0.0851,  0.4287])    1   \n",
      "tensor([ 0.4221, -0.7975])    0   \n",
      "tensor([-0.1078, -0.3783])    0   \n",
      "tensor([ 0.2468, -0.7811])    0   \n",
      "tensor([ 0.6513, -0.8174])    0   \n",
      "tensor([-0.1147, -0.3359])    0   \n",
      "tensor([ 0.7025, -0.8314])    0   \n",
      "tensor([ 0.4633, -0.4743])    0   \n",
      "tensor([ 0.4757, -0.9201])    0   \n",
      "tensor([ 2.9122, -1.6311])    0   \n",
      "tensor([-0.7718,  1.2143])    1   \n",
      "tensor([ 0.5687, -0.5766])    0   \n",
      "tensor([ 0.0801, -0.0121])    0   \n",
      "tensor([ 0.3223, -0.6378])    0   \n",
      "tensor([ 0.4890, -0.6970])    0   \n",
      "tensor([ 0.3435, -0.5816])    0   \n",
      "tensor([-0.4027, -0.2275])    1   \n",
      "tensor([-0.7417,  0.2346])    1   \n",
      "tensor([ 0.4081, -0.6497])    0   \n",
      "tensor([-0.4059,  0.2945])    1   \n",
      "tensor([ 0.4836, -0.2286])    0   \n",
      "tensor([-0.4821,  0.4666])    1   \n",
      "tensor([-0.0205, -0.8555])    0   \n",
      "tensor([-0.2565, -0.0253])    1   \n",
      "tensor([ 0.4628, -0.8712])    0   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([-0.0339, -0.2494])    0   \n",
      "tensor([ 2.5553, -1.6277])    0   \n",
      "tensor([-0.2482,  0.3732])    1   \n",
      "tensor([-0.4027, -0.2275])    1   \n",
      "tensor([ 0.4000, -0.7844])    0   \n",
      "tensor([-0.4335,  0.7610])    1   \n",
      "tensor([ 2.4573, -1.4584])    0   \n",
      "tensor([ 0.4694, -0.5913])    0   \n",
      "tensor([-0.6032,  0.2676])    1   \n",
      "tensor([-0.7053,  0.1960])    1   \n",
      "tensor([ 0.6270, -0.6418])    0   \n",
      "tensor([ 0.3095, -0.3696])    0   \n",
      "tensor([-0.6550,  0.8148])    1   \n",
      "tensor([ 0.7363, -0.9359])    0   \n",
      "tensor([ 0.3142, -0.8765])    0   \n",
      "tensor([-0.6263,  0.1324])    1   \n",
      "tensor([-0.9873,  0.7087])    1   \n",
      "tensor([ 0.0425, -0.0964])    0   \n",
      "tensor([ 0.3994, -0.5641])    0   \n",
      "tensor([-0.4628, -0.6223])    0   \n",
      "tensor([ 0.9377, -1.1021])    0   \n",
      "tensor([ 0.1419, -0.7615])    0   \n",
      "tensor([ 0.0054, -0.5999])    0   \n",
      "tensor([-0.0866, -0.4399])    0   \n",
      "tensor([-0.2564,  0.1009])    1   \n",
      "tensor([ 0.2635, -0.7505])    0   \n",
      "tensor([-0.4294,  0.3874])    1   \n",
      "tensor([ 0.3648, -0.7225])    0   \n",
      "tensor([ 0.6059, -0.8313])    0   \n",
      "tensor([-0.1270, -0.4022])    0   \n",
      "tensor([ 0.2883, -0.4678])    0   \n",
      "tensor([-0.5489,  0.6059])    1   \n",
      "tensor([-0.4934, -0.1710])    1   \n",
      "tensor([-0.0546, -0.0103])    1   \n",
      "tensor([ 0.4324, -0.9034])    0   \n",
      "tensor([ 0.8879, -0.7348])    0   \n",
      "tensor([-0.5027,  0.9269])    1   \n",
      "tensor([-0.0460, -0.5311])    0   \n",
      "tensor([-0.6469,  0.3241])    1   \n",
      "tensor([ 0.3205, -0.6784])    0   \n",
      "tensor([ 0.1712, -0.7824])    0   \n",
      "tensor([-0.9841,  0.4478])    1   \n",
      "tensor([ 0.3860, -0.5213])    0   \n",
      "tensor([-0.4188,  0.8712])    1   \n",
      "tensor([-0.1808,  0.6758])    1   \n",
      "tensor([-0.0747, -0.6151])    0   \n",
      "tensor([ 0.5209, -0.5014])    0   \n",
      "tensor([ 0.3744, -0.4226])    0   \n",
      "tensor([-0.5935,  0.4089])    1   \n",
      "tensor([-0.5106, -0.3710])    1   \n",
      "tensor([-0.3983,  0.6075])    1   \n",
      "tensor([-0.5110, -0.3708])    1   \n",
      "tensor([-0.7771,  0.2714])    1   \n",
      "tensor([ 0.0850, -0.5239])    0   \n",
      "tensor([ 0.4575, -0.8688])    0   \n",
      "tensor([-0.8307,  0.5543])    1   \n",
      "tensor([ 0.5249, -1.0209])    0   \n",
      "tensor([ 0.4575, -0.8688])    0   \n",
      "tensor([ 0.2902, -0.2967])    0   \n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST2 SET\n",
    "with torch.no_grad():\n",
    "    y_val2 = model2(cats2, conts2)\n",
    "\n",
    "rows = 418\n",
    "print(f'{\"MODEL OUTPUT\":26} ARGMAX')\n",
    "for i in range(rows):\n",
    "    print(f'{str(y_val2[i]):26} {y_val2[i].argmax():^7}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
